{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1406927,"sourceType":"datasetVersion","datasetId":822562}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sense2vec","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-05T12:54:47.701246Z","iopub.execute_input":"2024-10-05T12:54:47.701912Z","iopub.status.idle":"2024-10-05T12:55:00.989877Z","shell.execute_reply.started":"2024-10-05T12:54:47.701870Z","shell.execute_reply":"2024-10-05T12:55:00.988760Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sense2vec\n  Downloading sense2vec-2.0.2-py2.py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from sense2vec) (3.7.6)\nRequirement already satisfied: wasabi<1.2.0,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from sense2vec) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from sense2vec) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from sense2vec) (2.0.10)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from sense2vec) (1.26.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (8.2.5)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (70.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (3.4.1)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.0.0->sense2vec) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (0.1.2)\nDownloading sense2vec-2.0.2-py2.py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sense2vec\nSuccessfully installed sense2vec-2.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:55:00.992177Z","iopub.execute_input":"2024-10-05T12:55:00.993020Z","iopub.status.idle":"2024-10-05T12:55:12.577902Z","shell.execute_reply.started":"2024-10-05T12:55:00.992968Z","shell.execute_reply":"2024-10-05T12:55:12.576712Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:55:12.579676Z","iopub.execute_input":"2024-10-05T12:55:12.580656Z","iopub.status.idle":"2024-10-05T12:55:24.516935Z","shell.execute_reply.started":"2024-10-05T12:55:12.580604Z","shell.execute_reply":"2024-10-05T12:55:24.515762Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.3->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install python-Levenshtein","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:55:30.735045Z","iopub.execute_input":"2024-10-05T12:55:30.735954Z","iopub.status.idle":"2024-10-05T12:55:44.406887Z","shell.execute_reply.started":"2024-10-05T12:55:30.735907Z","shell.execute_reply":"2024-10-05T12:55:44.405911Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting python-Levenshtein\n  Downloading python_Levenshtein-0.26.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting Levenshtein==0.26.0 (from python-Levenshtein)\n  Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.0->python-Levenshtein)\n  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading python_Levenshtein-0.26.0-py3-none-any.whl (9.4 kB)\nDownloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\nSuccessfully installed Levenshtein-0.26.0 python-Levenshtein-0.26.0 rapidfuzz-3.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#import all the neccessary libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torch\nfrom sense2vec import Sense2Vec\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport nltk\nnltk.download('punkt')\nnltk.download('brown')\nnltk.download('wordnet')\nfrom nltk.corpus import wordnet as wn\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport Levenshtein\nimport pickle\nimport time\nimport os ","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:55:54.925408Z","iopub.execute_input":"2024-10-05T12:55:54.925833Z","iopub.status.idle":"2024-10-05T12:56:15.197583Z","shell.execute_reply.started":"2024-10-05T12:55:54.925794Z","shell.execute_reply":"2024-10-05T12:56:15.196581Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package brown to /usr/share/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"#getting the sentence transformer model and its tokenizer\n#sentence transformer model often integrates the tokenizer within the model class\n#we dont have to manage a separate tokenizer manually\nif os.path.exists(\"sentence_transformer_model.pkl\"):\n    with open(\"sentence_transformer_model.pkl\",'rb') as f:\n        sentence_transformer_model = pickle.load(f)\n    print(\"sentence transformer model found in the disc ---- model loaded successfully.\")\nelse:\n    print(\"sentence transformer model does not exist in the path specified ---- downloading the model from web.\")\n    start_time=time.time()\n    sentence_transformer_model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v2\")\n    end_time=time.time()\n\n    print(\"downloaded the sentence transformer in \",(end_time-start_time)/60,\" min, saving it to disc.\")\n\n    with open(\"sentence_transformer_model.pkl\",'wb') as f:\n        pickle.dump(sentence_transformer_model,f)\n\n    print(\"saved the sentence transformer to disc.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:56:40.286177Z","iopub.execute_input":"2024-10-05T12:56:40.286961Z","iopub.status.idle":"2024-10-05T12:56:45.499323Z","shell.execute_reply.started":"2024-10-05T12:56:40.286920Z","shell.execute_reply":"2024-10-05T12:56:45.498396Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"sentence transformer model does not exist in the path specified ---- downloading the model from web.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3cf2b6a8bd5434486dfd49cf8dae099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e23d4d84a54e81a18575f9f02acefa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd65771ac3524fec8e4b39c26a92a594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f5270192a44c4cb927bdf92ed84700"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96893b9bae246d88735d0c6f7270a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dcab862a36d46c0912f7c994db6019b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36671ad94e4b4f4996b3e7ff7b62b99c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55fcbdfe54b48508aa24824ec858080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7991fb205d714d858651d68f20b4449a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e45cf2cce9824db7a1436d211c0cff06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5927cc9542b4427a0a9747c5275d435"}},"metadata":{}},{"name":"stdout","text":"downloaded the sentence transformer in  0.07816810210545858  min, saving it to disc.\nsaved the sentence transformer to disc.\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_highest_similarity_score(wordlist,wrd):\n  \"\"\"\n  takes the given word along with the wordlist and then gives out the max-score which is the levenshtein distance for the wrong answers\n  because we need the options which are very different from one another but relating to the same context\n  \"\"\"\n  score=[]\n  for each in wordlist:\n    score.append(Levenshtein.ratio(each.lower(),wrd.lower()))\n  return max(score)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:56:49.188469Z","iopub.execute_input":"2024-10-05T12:56:49.188878Z","iopub.status.idle":"2024-10-05T12:56:49.195075Z","shell.execute_reply.started":"2024-10-05T12:56:49.188838Z","shell.execute_reply":"2024-10-05T12:56:49.194161Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"wordlist = [\"bench\", \"bark\", \"bloom\", \"blank\"]\ntarget_word = \"bank\"\n\nhighest_score = get_highest_similarity_score(wordlist, target_word)\n\nprint(\"Highest Similarity Score:\", highest_score)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:56:51.735730Z","iopub.execute_input":"2024-10-05T12:56:51.736123Z","iopub.status.idle":"2024-10-05T12:56:51.741516Z","shell.execute_reply.started":"2024-10-05T12:56:51.736085Z","shell.execute_reply":"2024-10-05T12:56:51.740604Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Highest Similarity Score: 0.8888888888888888\n","output_type":"stream"}]},{"cell_type":"code","source":"def filter_same_sense_words(original,wordlist):\n  \n  \"\"\"\n  filter the words which are of same sense, where it takes the wordlist which has the sense of the word attached as the string along with the word itself.\n  \"\"\"\n  filtered_words=[]\n  base_sense =original.split('|')[1] \n  \n  for eachword in wordlist:\n    if eachword[0].split('|')[1] == base_sense:\n      filtered_words.append(eachword[0].split('|')[0].replace(\"_\", \" \").title().strip())\n  return filtered_words","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:56:54.078417Z","iopub.execute_input":"2024-10-05T12:56:54.079309Z","iopub.status.idle":"2024-10-05T12:56:54.085139Z","shell.execute_reply.started":"2024-10-05T12:56:54.079265Z","shell.execute_reply":"2024-10-05T12:56:54.084178Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"original = \"bank|financial_institution\"\nwordlist = [\n    [\"bank|financial_institution\"],\n    [\"river_bank|location\"],\n    [\"credit_union|financial_institution\"],\n    [\"savings_bank|financial_institution\"],\n    [\"shore|location\"]\n]\n\nfiltered = filter_same_sense_words(original, wordlist)\n\nprint(\"Filtered Words:\", filtered)\n#filtered words that have the same sense as the original word","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:56:56.011563Z","iopub.execute_input":"2024-10-05T12:56:56.012463Z","iopub.status.idle":"2024-10-05T12:56:56.017986Z","shell.execute_reply.started":"2024-10-05T12:56:56.012418Z","shell.execute_reply":"2024-10-05T12:56:56.017084Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Filtered Words: ['Bank', 'Credit Union', 'Savings Bank']\n","output_type":"stream"}]},{"cell_type":"code","source":"from sense2vec import Sense2Vec\n\n#load the sense2vec model from the uploaded directory\ns2v = Sense2Vec().from_disk('/kaggle/input/s2v-old/s2v_old')\nprint(\"sense2vec model loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:56:58.462488Z","iopub.execute_input":"2024-10-05T12:56:58.463002Z","iopub.status.idle":"2024-10-05T12:57:11.577773Z","shell.execute_reply.started":"2024-10-05T12:56:58.462963Z","shell.execute_reply":"2024-10-05T12:57:11.576831Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"sense2vec model loaded successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"def sense2vec_get_words(word,s2v,topn,question):\n    \"\"\"\n    This function takes the input word, sentence to vector model and top similar words and also the question\n    Then it computes the sense of the given word\n    then it gets the words which are of same sense but are most similar to the given word\n    after that we we return the list of words which satisfy the above mentioned criteria\n    \"\"\"\n    output = []\n#     print (\"word \",word)\n    try:\n      sense = s2v.get_best_sense(word, senses= [\"NOUN\", \"PERSON\",\"PRODUCT\",\"LOC\",\"ORG\",\"EVENT\",\"NORP\",\"WORK OF ART\",\"FAC\",\"GPE\",\"NUM\",\"FACILITY\"])\n#       print(sense)\n      most_similar = s2v.most_similar(sense, n=topn)\n#       print (most_similar)\n      output = filter_same_sense_words(sense,most_similar)\n#       print (\"Similar \",output)\n    except:\n      output =[]\n\n    threshold = 0.6\n    final=[word]\n    checklist =question.split()\n    for x in output:\n      if get_highest_similarity_score(final,x)<threshold and x not in final and x not in checklist:\n        final.append(x)\n    \n    return final[1:]","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:57:49.617626Z","iopub.execute_input":"2024-10-05T12:57:49.618332Z","iopub.status.idle":"2024-10-05T12:57:49.626014Z","shell.execute_reply.started":"2024-10-05T12:57:49.618278Z","shell.execute_reply":"2024-10-05T12:57:49.624865Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"word = 'bank'\ntopn = 10\nquestion = \"What is the bank's interest rate on savings?\"\n\nsimilar_words = sense2vec_get_words(word, s2v, topn, question)\n\n#output the similar words\nprint(\"Similar words to '{}': {}\".format(word, similar_words))","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:57:51.894276Z","iopub.execute_input":"2024-10-05T12:57:51.895179Z","iopub.status.idle":"2024-10-05T12:57:53.258414Z","shell.execute_reply.started":"2024-10-05T12:57:51.895112Z","shell.execute_reply":"2024-10-05T12:57:53.257377Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Similar words to 'bank': ['Local Bank', 'Bank Account', 'Cash Deposits', 'Financial Institution', 'Cash', 'Different Bank']\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nMaximal Marginal Relevance (MMR) algorithm to extract keywords or keyphrases from a document \nwhile balancing relevance and diversity\n- vector representing the document's content\n- matrix of word embeddings where each row corresponds to the embedding of a word in the vocabulary.\n- list of words or keyphrases from which keywords will be selected\n- number of keywords/keyphrases to extract from the document\n\"\"\"\ndef mmr(doc_embedding, word_embeddings, words, top_n, lambda_param):\n    \"\"\"\n    The mmr function takes document and word embeddings, along with other parameters, \n    and uses the Maximal Marginal Relevance (MMR) algorithm to extract a specified number of keywords/keyphrases \n    from the document. The MMR algorithm balances the relevance of keywords with their diversity, \n    helping to select keywords that are both informative and distinct from each other.\n    \"\"\"\n\n    #extract similarity within words, and between words and the document\n    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n    word_similarity = cosine_similarity(word_embeddings)\n\n    #initialize candidates and already choose best keyword/keyphrase\n    keywords_idx = [np.argmax(word_doc_similarity)]\n    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n\n    for _ in range(top_n - 1):\n        #extract similarities within candidates and\n        #between candidates and selected keywords/phrases\n        candidate_similarities = word_doc_similarity[candidates_idx, :]\n        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n\n        #calculate MMR\n        mmr = (lambda_param) * candidate_similarities - (1-lambda_param) * target_similarities.reshape(-1, 1)\n        mmr_idx = candidates_idx[np.argmax(mmr)]\n\n        #update keywords & candidates\n        keywords_idx.append(mmr_idx)\n        candidates_idx.remove(mmr_idx)\n\n    return [words[idx] for idx in keywords_idx]","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:57:55.310634Z","iopub.execute_input":"2024-10-05T12:57:55.311439Z","iopub.status.idle":"2024-10-05T12:57:55.320090Z","shell.execute_reply.started":"2024-10-05T12:57:55.311397Z","shell.execute_reply":"2024-10-05T12:57:55.319189Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_distractors (word,origsentence,sense2vecmodel,sentencemodel,top_n,lambdaval):\n  \"\"\"\n  this function generates distractor words (answer choices) for a given target word in the context of a provided sentence. \n  It selects distractors based on their similarity to the target word's context and ensures that the target word itself \n  is not included among the distractors. This function is useful for creating multiple-choice questions or answer \n  options in natural language processing tasks.\n  \"\"\"\n  distractors = sense2vec_get_words(word,sense2vecmodel,top_n,origsentence)\n  #print (\"distractors \",distractors)\n  if len(distractors) ==0:\n    return distractors\n  distractors_new = [word.capitalize()]\n  distractors_new.extend(distractors)\n  # print (\"distractors_new .. \",distractors_new)\n\n  embedding_sentence = origsentence+ \" \"+word.capitalize()\n  # embedding_sentence = word\n  keyword_embedding = sentencemodel.encode([embedding_sentence])\n  distractor_embeddings = sentencemodel.encode(distractors_new)\n\n  # filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors,4,0.7)\n  max_keywords = min(len(distractors_new),5)\n  filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors_new,max_keywords,lambdaval)\n  # filtered_keywords = filtered_keywords[1:]\n  final = [word.capitalize()]\n  for wrd in filtered_keywords:\n    if wrd.lower() !=word.lower():\n      final.append(wrd.capitalize())\n  final = final[1:]\n  return final","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:57:57.778340Z","iopub.execute_input":"2024-10-05T12:57:57.778736Z","iopub.status.idle":"2024-10-05T12:57:57.786946Z","shell.execute_reply.started":"2024-10-05T12:57:57.778698Z","shell.execute_reply":"2024-10-05T12:57:57.786035Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#target word and original sentence\nword = \"dog\"\norigsentence = \"The dog barked loudly.\"\n\ntop_n = 5  #number of top similar words\nlambdaval = 0.5  #balance parameter for MMR\n\ndistractors = get_distractors(word, origsentence, s2v, sentence_transformer_model, top_n, lambdaval)\n\n# Output the distractors\nprint(\"Distractors for '{}': {}\".format(word, distractors))","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:58:01.484970Z","iopub.execute_input":"2024-10-05T12:58:01.485798Z","iopub.status.idle":"2024-10-05T12:58:03.278009Z","shell.execute_reply.started":"2024-10-05T12:58:01.485754Z","shell.execute_reply":"2024-10-05T12:58:03.277154Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b20267863294774a2dfacc148119766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcf159c277c54ee8b0ff88a41490ccd6"}},"metadata":{}},{"name":"stdout","text":"Distractors for 'dog': ['Kitten', 'Puppy', 'Cat']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}