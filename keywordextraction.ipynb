{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1406927,"sourceType":"datasetVersion","datasetId":822562}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:00:33.662481Z","iopub.execute_input":"2024-10-05T12:00:33.662844Z","iopub.status.idle":"2024-10-05T12:00:45.450858Z","shell.execute_reply.started":"2024-10-05T12:00:33.662804Z","shell.execute_reply":"2024-10-05T12:00:45.449816Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (3.1.1)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.3->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"#import all the neccessary libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torch\nimport pickle\nimport time\nimport os \nfrom transformers import T5ForConditionalGeneration,T5Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:00:57.252117Z","iopub.execute_input":"2024-10-05T12:00:57.252445Z","iopub.status.idle":"2024-10-05T12:00:57.257870Z","shell.execute_reply.started":"2024-10-05T12:00:57.252409Z","shell.execute_reply":"2024-10-05T12:00:57.256786Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:00:59.230378Z","iopub.execute_input":"2024-10-05T12:00:59.230795Z","iopub.status.idle":"2024-10-05T12:00:59.236219Z","shell.execute_reply.started":"2024-10-05T12:00:59.230756Z","shell.execute_reply":"2024-10-05T12:00:59.235308Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration,T5Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:01.448841Z","iopub.execute_input":"2024-10-05T12:01:01.449646Z","iopub.status.idle":"2024-10-05T12:01:01.454627Z","shell.execute_reply.started":"2024-10-05T12:01:01.449601Z","shell.execute_reply":"2024-10-05T12:01:01.453385Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#getting the summary model and its tokenizer\nif os.path.exists(\"t5_summary_model.pkl\"):\n    with open('t5_summary_model.pkl', 'rb') as f:\n        summary_model = pickle.load(f)\n    print(\"summary model found in the disc ---- model loaded successfully.\")\n\nelse:\n    print(\"summary model does not exist in the path specified ---- downloading the model from web.\")\n    start_time = time.time()\n    summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n    end_time = time.time()\n\n    print(\"downloaded the summary model in \",(end_time-start_time)/60,\" min, saving it to disc.\")\n\n    with open(\"t5_summary_model.pkl\", 'wb') as f:\n        pickle.dump(summary_model,f)\n    \n    print(\"saved the model to disc.\")\n\nif os.path.exists(\"t5_summary_tokenizer.pkl\"):\n    with open('t5_summary_tokenizer.pkl', 'rb') as f:\n        summary_tokenizer = pickle.load(f)\n    print(\"summary tokenizer found in the disc ---- loaded successfully.\")\nelse: \n    print(\"summary tokenizer does not exist in the path specified ---- downloading the model from web.\")\n\n    start_time = time.time()\n    summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n    end_time = time.time()\n\n    print(\"downloaded the summary tokenizer in \",(end_time-start_time)/60,\" min, saving it to disc.\")\n\n    with open(\"t5_summary_tokenizer.pkl\",'wb') as f:\n        pickle.dump(summary_tokenizer,f)\n\n    print(\"saved the tokenizer to disc.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:03.965706Z","iopub.execute_input":"2024-10-05T12:01:03.966415Z","iopub.status.idle":"2024-10-05T12:01:04.965763Z","shell.execute_reply.started":"2024-10-05T12:01:03.966371Z","shell.execute_reply":"2024-10-05T12:01:04.964671Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"summary model found in the disc ---- model loaded successfully.\nsummary tokenizer found in the disc ---- loaded successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"summary_model = summary_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:07.951808Z","iopub.execute_input":"2024-10-05T12:01:07.952798Z","iopub.status.idle":"2024-10-05T12:01:08.181512Z","shell.execute_reply.started":"2024-10-05T12:01:07.952737Z","shell.execute_reply":"2024-10-05T12:01:08.180510Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#test\ninput_text = \"Climate change is one of the most pressing issues facing our planet today. As average temperatures rise due to increased greenhouse gas emissions, ecosystems around the world are experiencing significant shifts. Polar regions are warming at an alarming rate, leading to the melting of glaciers and the loss of habitats for species such as polar bears and seals.In temperate regions, changes in temperature and precipitation patterns are affecting plant and animal life cycles. For example, many species are blooming earlier in the spring, which can disrupt the food chain and impact pollinators like bees. In tropical regions, coral reefs, which are vital for marine biodiversity, are suffering from coral bleaching due to rising sea temperatures and ocean acidification.The effects of climate change are not only limited to natural ecosystems; they also impact human societies. Changes in weather patterns can lead to food and water shortages, displacement of populations, and increased health risks due to heatwaves and the spread of diseases. Mitigating the effects of climate change requires collective action on a global scale, including reducing carbon emissions, transitioning to renewable energy sources, and promoting sustainable land use practices.Addressing climate change is not only essential for preserving biodiversity but also crucial for ensuring the well-being of future generations.\"\n\n#tokenize the input text\ninput_ids = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True).to(device)\n\n#generate the summary\nwith torch.no_grad():\n    summary_ids = summary_model.generate(\n        input_ids,\n        max_length=150,  #desired max length for the summary\n        min_length=40,   #desired min length for the summary\n        length_penalty=2.0,\n        num_beams=4,\n        early_stopping=True\n    )\n\n#decode the summary\nsummary = summary_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n#print the generated summary\nprint(\"Summary:\", summary)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:10.557556Z","iopub.execute_input":"2024-10-05T12:01:10.557979Z","iopub.status.idle":"2024-10-05T12:01:12.079508Z","shell.execute_reply.started":"2024-10-05T12:01:10.557943Z","shell.execute_reply":"2024-10-05T12:01:12.078310Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Summary: plant and animal life cycles are disrupting the food chain and impacting pollinators like bees. In tropical regions, coral reefs are suffering from coral bleaching due to rising sea temperatures and ocean acidification. Climate change is one of the most pressing issues facing our planet today.Mitigating the effects of climate change requires collective action on a global scale.\n","output_type":"stream"}]},{"cell_type":"code","source":"def summarizer(text,model,tokenizer):\n  \"\"\"\n  takes the given text along with the model and tokenizer, which summarize the large text into useful information\n  \"\"\"\n  text = text.strip().replace(\"\\n\",\" \")\n  text = \"summarize: \"+text\n#   print (text)\n    \n  #tokenize the input text\n  max_len = 512\n  encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n\n  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n\n  #generate summmmary\n  outs = model.generate(input_ids=input_ids,\n                                  attention_mask=attention_mask,\n                                  early_stopping=True,\n                                  num_beams=3,\n                                  num_return_sequences=1,\n                                  no_repeat_ngram_size=2,\n                                  min_length = 75,\n                                  max_length=300)\n\n  #decode the summary and apply postprocessing\n  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n  summary = dec[0]\n  summary = postprocesstext(summary)\n  summary= summary.strip()\n\n  return summary","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:13.654936Z","iopub.execute_input":"2024-10-05T12:01:13.655307Z","iopub.status.idle":"2024-10-05T12:01:13.663777Z","shell.execute_reply.started":"2024-10-05T12:01:13.655273Z","shell.execute_reply":"2024-10-05T12:01:13.662924Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"text = \"\"\"\nThe transformer architecture, introduced in 2017 by Vaswani et al., revolutionized natural language processing (NLP) by moving away from recurrent neural networks (RNNs) and convolutional neural networks (CNNs). Instead, the transformer relies entirely on attention mechanisms to draw global dependencies between input and output. The self-attention mechanism allows the model to weigh the importance of different words in a sentence relative to each other, enabling it to capture more complex relationships in text. This has made the transformer highly efficient for tasks such as machine translation, text summarization, and language modeling.\nBefore transformers, RNNs and their variants, such as Long Short-Term Memory (LSTM) networks, were the dominant models for sequence processing tasks. These models processed inputs sequentially, which limited their ability to handle long-range dependencies. The transformer, on the other hand, processes the entire sequence simultaneously, making it faster and more effective for long sequences. It also allows for better parallelization during training, significantly reducing the time required to train large models.\n\"\"\"\nsummary = summarizer(text, summary_model, summary_tokenizer)\nprint(\"summary\")\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:16.320056Z","iopub.execute_input":"2024-10-05T12:01:16.320883Z","iopub.status.idle":"2024-10-05T12:01:17.931433Z","shell.execute_reply.started":"2024-10-05T12:01:16.320835Z","shell.execute_reply":"2024-10-05T12:01:17.930447Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"summary\nThe transformer architecture revolutionized natural language processing (nlp) it relies entirely on attention mechanisms to draw global dependencies between input and output . This has made it highly efficient for tasks such as machine translation, text summarization, and language modeling. Transformer processes the entire sequence simultaneously, making it faster and more effective for long sequences. Cnn.com/nlp/2017/02/13\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_nouns_multipartite(content):\n    \"\"\"\n    takes the content text given and then outputs the phrases which are build around the nouns , \n    so that we can use them for context based distractors\n    extract key phrases centered around nouns from a given text using the pke library's MultipartiteRank model\n    \"\"\"\n    out=[] #store the extracted key phrases\n    \n    try:\n        \"\"\"\n        an instance of the MultipartiteRank class from the pke (Python Keyphrase Extraction) library is created\n        \"\"\"\n        extractor = pke.unsupervised.MultipartiteRank()\n        extractor.load_document(input=content,language='en') #loads the input text\n        #not contain punctuation marks or stopwords as candidates.\n        #pos = {'PROPN','NOUN',}\n        #defines the parts of speech (POS) that will be considered for candidate selection\n        pos = {'PROPN', 'NOUN', 'ADJ', 'VERB', 'ADP', 'ADV', 'DET', 'CONJ', 'NUM', 'PRON', 'X'}\n\n        #filter out common punctuation marks and stop words from English\n        stoplist = list(string.punctuation)\n        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-'] #specific tokens for parentheses and brackets \n        stoplist += stopwords.words('english') #list of common English stopwords obtained from NLTK (like \"the\", \"is\", etc.).\n        \n        # extractor.candidate_selection(pos=pos, stoplist=stoplist)\n        #identifies potential key phrases based on the given POS tags\n        extractor.candidate_selection( pos=pos)\n        # 4. build the Multipartite graph and rank candidates using random walk,\n        #    alpha controls the weight adjustment mechanism, see TopicRank for\n        #    threshold/method parameters.\n        extractor.candidate_weighting(alpha=1.1,\n                                      threshold=0.75,\n                                      method='average')\n        keyphrases = extractor.get_n_best(n=15)\n        \n\n        for val in keyphrases:\n            out.append(val[0])\n    except:\n        out = []\n        #traceback.print_exc()\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:20.378954Z","iopub.execute_input":"2024-10-05T12:01:20.379391Z","iopub.status.idle":"2024-10-05T12:01:20.388870Z","shell.execute_reply.started":"2024-10-05T12:01:20.379349Z","shell.execute_reply":"2024-10-05T12:01:20.387832Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def get_keywords(originaltext):\n  #just a simpler name\n  keywords = get_nouns_multipartite(originaltext)\n  return keywords","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:23.505590Z","iopub.execute_input":"2024-10-05T12:01:23.506285Z","iopub.status.idle":"2024-10-05T12:01:23.511080Z","shell.execute_reply.started":"2024-10-05T12:01:23.506243Z","shell.execute_reply":"2024-10-05T12:01:23.509973Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"originaltext = \"\"\"\nNatural Language Processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language.\nThe ultimate goal of NLP is to enable computers to understand, interpret, and generate human language in a valuable way.\nRecent advancements in NLP have been driven by the development of transformer models, which have significantly improved the performance of various language tasks, including machine translation, sentiment analysis, and summarization.\n\"\"\"\nextracted_keywords = get_keywords(originaltext)\n\nprint(\"Extracted Keywords:\", extracted_keywords)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:26.001332Z","iopub.execute_input":"2024-10-05T12:01:26.002442Z","iopub.status.idle":"2024-10-05T12:01:27.289499Z","shell.execute_reply.started":"2024-10-05T12:01:26.002386Z","shell.execute_reply":"2024-10-05T12:01:27.288447Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Extracted Keywords: ['understand', 'sentiment analysis', 'enable computers', 'interpret', 'including machine translation', 'nlp', 'natural language processing', 'summarization']\n","output_type":"stream"}]},{"cell_type":"code","source":"summarized_text = summarizer(originaltext,summary_model,summary_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:30.704931Z","iopub.execute_input":"2024-10-05T12:01:30.706094Z","iopub.status.idle":"2024-10-05T12:01:32.254589Z","shell.execute_reply.started":"2024-10-05T12:01:30.706047Z","shell.execute_reply":"2024-10-05T12:01:32.253568Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"summarized_text","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:36.409711Z","iopub.execute_input":"2024-10-05T12:01:36.410669Z","iopub.status.idle":"2024-10-05T12:01:36.416818Z","shell.execute_reply.started":"2024-10-05T12:01:36.410624Z","shell.execute_reply":"2024-10-05T12:01:36.415942Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"'Natural language processing (nlp) is a subfield of artificial intelligence (ai) the goal of nlp is to enable computers to understand, interpret, and generate human language . Transformer models have significantly improved the performance of various language tasks, including machine translation, sentiment analysis and summarization. The transformer model is an example of how transformers can be used to analyze human speech.'"},"metadata":{}}]},{"cell_type":"code","source":"get_keywords(originaltext)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:45.466392Z","iopub.execute_input":"2024-10-05T12:01:45.467189Z","iopub.status.idle":"2024-10-05T12:01:46.690130Z","shell.execute_reply.started":"2024-10-05T12:01:45.467145Z","shell.execute_reply":"2024-10-05T12:01:46.689079Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"['understand',\n 'sentiment analysis',\n 'enable computers',\n 'interpret',\n 'including machine translation',\n 'nlp',\n 'natural language processing',\n 'summarization']"},"metadata":{}}]},{"cell_type":"code","source":"get_keywords(summarized_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:01:49.334944Z","iopub.execute_input":"2024-10-05T12:01:49.335664Z","iopub.status.idle":"2024-10-05T12:01:51.098349Z","shell.execute_reply.started":"2024-10-05T12:01:49.335622Z","shell.execute_reply":"2024-10-05T12:01:51.097368Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"['transformer models',\n 'generate human language',\n 'understand',\n 'interpret',\n 'sentiment analysis',\n 'enable computers',\n 'including machine translation',\n 'summarization',\n 'nlp',\n 'natural language processing',\n 'analyze human speech',\n 'transformers']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}